/media/cc/2T/liouvilleViT/train_masked_blocks.py:126: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()  # Initialize GradScaler for mixed precision

--- Epoch 1/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
/media/cc/2T/liouvilleViT/train_masked_blocks.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.263954
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.278548
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.261683
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.268430
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.261612
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.260208
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.260330
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.256852
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.253582
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.255354
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.252195
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.251923
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.253869
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.264446
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.250037
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.247851
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.245708
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.243234
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.246118
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.244680
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.240592
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.240036
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.236934
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.238891
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.234290
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.257370
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.229766
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.235169
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.240098
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.231812
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.228437
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.226859
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.229633
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.222337
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.219408
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.216807
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.216669
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.212921
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.214183
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.208975
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.207072
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.207611
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.210744
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.201524
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.199901
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.197416
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.203073
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.194126
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.198101
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.189757
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.184135
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.191985
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.177190
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.180491
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.178553
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.181208
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.172800
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.170658
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.167678
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.164165
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.157962
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.155099
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.159240
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.151623
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.146340
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.146215
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.143848
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.140529
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.134503
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.132934
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.133062
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.126829
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.125052
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.123551
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.118694
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.115383
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.117889
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.112063
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.111081
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.107095
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.103832
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.102427
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.101667
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.099442
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.101550
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.097958
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.100275
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.095156
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.094487
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.095244
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.092176
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.091706
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.102634
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.091238
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.091901
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.091225
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.093660
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.094834
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.093437
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.094436
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
Epoch 1 | Loss: 0.180683 | MSE: 0.092887 | MAE: 0.213714 | PSNR: 10.32 dB
About to log to wandb: {'epoch': 1, 'train_loss': 0.1806826835870743, 'eval_mse': np.float32(0.09288675), 'eval_mae': np.float32(0.21371432), 'eval_psnr': 10.320461728346842}
Logged to wandb.
    Saved comparison image: block_comparisons/epoch_001_block_00000.png
    Saved comparison image: block_comparisons/epoch_001_block_00002.png
    Saved comparison image: block_comparisons/epoch_001_block_00004.png
About to save model checkpoint.
Model checkpoint saved.
 Saved new best model at epoch 1 (MSE: 0.092887)

--- Epoch 2/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
/media/cc/2T/liouvilleViT/train_masked_blocks.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.095055
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.092291
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.092826
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.088390
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.089313
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.092409
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.092300
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.097365
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.088683
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.089256
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.092847
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.090937
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.089265
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.090755
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.086839
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.094295
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.090473
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.090465
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.087433
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.093912
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.088994
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.088928
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.091049
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.089240
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.098556
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.090384
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.090304
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.088485
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.097952
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.091103
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.091142
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.087776
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.089387
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.092670
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.087657
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.089169
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.089933
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.088351
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.088755
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.088087
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.088690
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.088264
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.087938
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.087209
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.089736
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.089281
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.088722
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.090986
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.089479
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.090605
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.092102
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.088361
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.107671
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.089724
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.090573
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.088999
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.090696
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.090402
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.089891
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.089955
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.087896
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.089071
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.091418
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.095472
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.089832
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.089105
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.089215
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.090863
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.087856
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.087821
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.098190
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.089226
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.091072
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.091057
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.096811
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.087643
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.087641
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.088891
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.086545
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.089488
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.087461
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.087928
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.089816
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.089658
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.088663
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.088541
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.088698
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.089163
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.086931
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.090090
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.087722
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.088968
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.089134
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.089670
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.090244
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.091528
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.088584
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.088079
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.087781
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.089210
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
Epoch 2 | Loss: 0.090253 | MSE: 0.100208 | MAE: 0.203287 | PSNR: 9.99 dB
About to log to wandb: {'epoch': 2, 'train_loss': 0.09025291040539742, 'eval_mse': np.float32(0.10020783), 'eval_mae': np.float32(0.20328714), 'eval_psnr': 9.990983157444132}
Logged to wandb.
    Saved comparison image: block_comparisons/epoch_002_block_00006.png
    Saved comparison image: block_comparisons/epoch_002_block_00003.png
    Saved comparison image: block_comparisons/epoch_002_block_00000.png

--- Epoch 3/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.089346
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.089294
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.089088
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.089463
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.089958
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.097129
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.088474
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.087361
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.089869
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.093746
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.092640
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.088722
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.088804
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.088600
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.090379
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.087617
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.087931
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.087436
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.088340
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.091480
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.087676
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.086923
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.088985
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.088657
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.089575
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.088415
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.088665
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.088483
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.089341
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.088780
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.088823
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.092670
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.091017
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.089775
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.093867
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.088047
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.087534
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.089159
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.088865
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.091081
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.088190
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.087100
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.087779
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.095364
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.087029
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.091062
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.097367
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.088980
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.088698
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.088869
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.089472
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.088967
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.089958
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.093268
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.088935
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.088069
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.089725
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.092651
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.087165
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.088923
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.088584
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.088457
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.087853
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.087878
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.086038
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.088464
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.088514
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.089038
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.089101
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.087762
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.088585
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.087179
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.087671
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.088456
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.088921
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.087464
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.088959
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.088202
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.091181
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.088915
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.090380
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.089489
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.088775
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.089422
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.085512
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.089502
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.094160
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.087060
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.087088
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.089026
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.087916
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.089388
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.087572
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.087534
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.091574
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.092890
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.090173
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.088681
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.088066
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.091441
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
Epoch 3 | Loss: 0.089325 | MSE: 0.090238 | MAE: 0.193762 | PSNR: 10.45 dB
About to log to wandb: {'epoch': 3, 'train_loss': 0.08932457327842712, 'eval_mse': np.float32(0.09023809), 'eval_mae': np.float32(0.19376208), 'eval_psnr': 10.446101017302816}
Logged to wandb.
    Saved comparison image: block_comparisons/epoch_003_block_00000.png
    Saved comparison image: block_comparisons/epoch_003_block_00002.png
    Saved comparison image: block_comparisons/epoch_003_block_00006.png
About to save model checkpoint.
Model checkpoint saved.
 Saved new best model at epoch 3 (MSE: 0.090238)

--- Epoch 4/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.089553
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.096682
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.088589
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.091482
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.088692
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.087425
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.084514
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.095453
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.093129
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.086876
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.088251
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.087274
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.090091
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.088302
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.087899
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.088700
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.088302
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.089754
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.089202
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.093899
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.088149
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.087335
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.086779
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.094213
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.088976
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.089745
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.089443
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.087281
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.086703
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.087329
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.087326
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.094028
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.090005
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.087709
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.087882
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.090540
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.088450
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.087682
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.092881
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.087630
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.087658
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.087946
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.090884
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.092879
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.088164
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.093546
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.092197
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.087293
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.088652
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.090983
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.093217
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.087028
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.091161
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.090606
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.088223
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.087751
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.088802
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.085993
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.087539
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.090039
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.089272
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.089804
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.091207
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.089126
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.087089
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.086882
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.088472
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.090419
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.089596
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.087443
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.086396
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.086243
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.090300
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.086380
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.092645
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.087957
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.089878
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.085902
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.088238
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.086620
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.089071
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.087190
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.086438
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.088231
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.093323
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.090196
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.086744
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.089998
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.088206
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.087896
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.089377
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.085612
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.088487
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.090908
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.088824
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.088976
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.087198
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.090068
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.086056
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.088607
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
Epoch 4 | Loss: 0.089060 | MSE: 0.085765 | MAE: 0.188208 | PSNR: 10.67 dB
About to log to wandb: {'epoch': 4, 'train_loss': 0.089059893861413, 'eval_mse': np.float32(0.08576473), 'eval_mae': np.float32(0.18820775), 'eval_psnr': 10.666912628623518}
Logged to wandb.
    Saved comparison image: block_comparisons/epoch_004_block_00009.png
    Saved comparison image: block_comparisons/epoch_004_block_00005.png
    Saved comparison image: block_comparisons/epoch_004_block_00004.png
About to save model checkpoint.
Model checkpoint saved.
 Saved new best model at epoch 4 (MSE: 0.085765)

--- Epoch 5/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.092487
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.088883
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.088185
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.089369
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.088438
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.093865
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.089271
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.085804
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.090731
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.085718
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.096147
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.091046
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.087902
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.091902
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.090111
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.091680
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.089151
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.088178
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.088548
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.089701
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.088145
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.087524
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.086981
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.087208
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.088960
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.086130
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.091297
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.086597
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.088452
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.093094
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.090043
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.095046
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.095500
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.088681
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.088164
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.088248
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.091001
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.088194
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.088222
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.091080
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.088568
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.088428
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.088536
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.087396
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.088813
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.087158
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.088422
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.094897
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.088490
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.087019
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.089460
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.090371
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.089355
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.091829
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.090634
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.086994
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.087516
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.086451
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.088440
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.086965
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.087565
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.088163
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.087638
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.085352
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.091976
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.089082
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.085991
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.088318
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.087189
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.088714
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.086766
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.092452
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.089001
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.086063
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.085949
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.086996
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.088052
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.088069
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.087901
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.085462
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.089461
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.086038
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.086307
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.086988
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.087099
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.087940
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.086917
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.087914
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.085731
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.086564
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.089936
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.088343
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.087074
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.091431
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.088261
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.086436
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.087332
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.094713
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.089734
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.086781
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
Epoch 5 | Loss: 0.088791 | MSE: 0.086540 | MAE: 0.188479 | PSNR: 10.63 dB
About to log to wandb: {'epoch': 5, 'train_loss': 0.08879126995801925, 'eval_mse': np.float32(0.0865402), 'eval_mae': np.float32(0.18847868), 'eval_psnr': 10.627820763314897}
Logged to wandb.
    Saved comparison image: block_comparisons/epoch_005_block_00005.png
    Saved comparison image: block_comparisons/epoch_005_block_00007.png
    Saved comparison image: block_comparisons/epoch_005_block_00006.png

--- Epoch 6/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.107684
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.088859
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.086778
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.085448
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.089121
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.085161
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.086061
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.087160
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.086759
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.089663
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.085786
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.092302
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.093821
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.086532
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.087854
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.089579
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.086710
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.088494
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.099690
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.087217
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.085686
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.090210
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.086329
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.085333
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.087298
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.091378
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.092352
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.088080
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.096783
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.089549
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.089753
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.093089
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.084840
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.090394
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.085796
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.088403
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.087329
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.084788
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.087961
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.087619
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.085347
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.091130
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.089940
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.093578
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.085896
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.090678
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.087687
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.090644
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.090578
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.090154
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.094858
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.088926
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.086052
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.090796
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.088294
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.089742
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.089857
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.087356
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.087107
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.085847
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.087938
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.090432
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.090330
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.090866
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.088002
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.090282
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.087448
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.086343
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.088311
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.086693
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.089188
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.093890
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.086868
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.088664
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.088583
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.089095
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.093982
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.087130
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.086268
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.086431
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.088213
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.090722
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.095198
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.093267
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.088043
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.086306
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.087393
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.087677
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.087235
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.091558
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.090199
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.089873
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.086010
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.088186
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.086493
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.089432
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.086910
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.090698
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.097074
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.086248
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
Epoch 6 | Loss: 0.089116 | MSE: 0.088107 | MAE: 0.189733 | PSNR: 10.55 dB
About to log to wandb: {'epoch': 6, 'train_loss': 0.08911592707037926, 'eval_mse': np.float32(0.08810726), 'eval_mae': np.float32(0.18973252), 'eval_psnr': 10.549882858831236}
Logged to wandb.
    Saved comparison image: block_comparisons/epoch_006_block_00000.png
    Saved comparison image: block_comparisons/epoch_006_block_00005.png
    Saved comparison image: block_comparisons/epoch_006_block_00006.png

--- Epoch 7/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.087163
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.086601
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.093464
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.086651
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.086496
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.090155
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.087222
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.087069
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.092952
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.086673
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.088173
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.087432
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.086868
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.087741
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.085438
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.086944
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.084645
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.085664
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.089948
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.089538
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.090202
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.086932
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.088049
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.089583
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.090358
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.087065
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.087722
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.087318
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.095345
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.094548
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.087156
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.089368
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.086077
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.110598
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.087446
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.088763
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.086210
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.094314
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.088055
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.086696
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.087478
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.088035
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.089817
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.089239
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.090653
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.087717
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.090061
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.088616
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.085966
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.092410
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.089942
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.088103
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.088918
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.090026
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.084960
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.088457
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.098128
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.087783
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.087000
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.098298
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.088428
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.088097
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.096717
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.086997
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.088835
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.087828
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.089860
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.084714
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.088505
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.086979
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.088064
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.086258
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.088778
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.090825
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.096719
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.088163
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.087653
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.086289
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.086542
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.088277
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.089351
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.090215
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.088639
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.085862
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.088726
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.088145
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.088832
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.090483
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.088323
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.088593
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.087695
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.086752
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.088080
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.086342
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.087571
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.091219
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.088266
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.087866
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.088674
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.087786
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
Epoch 7 | Loss: 0.088922 | MSE: 0.088140 | MAE: 0.188734 | PSNR: 10.55 dB
About to log to wandb: {'epoch': 7, 'train_loss': 0.08892198763787747, 'eval_mse': np.float32(0.088139795), 'eval_mae': np.float32(0.1887339), 'eval_psnr': 10.548279110011766}
Logged to wandb.
    Saved comparison image: block_comparisons/epoch_007_block_00005.png
    Saved comparison image: block_comparisons/epoch_007_block_00008.png
    Saved comparison image: block_comparisons/epoch_007_block_00009.png

--- Epoch 8/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.086254
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.087381
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.088721
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.087903
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.089444
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.086483
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.086434
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.087065
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.086700
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.088267
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.088852
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.087349
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.086852
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.086970
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.090581
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.086568
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.087768
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.085895
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.088614
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.090042
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.089406
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.088308
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.087692
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.087092
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.088377
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.086420
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.089405
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.090369
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.088007
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.090011
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.087391
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.087614
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.087287
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.089672
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.089541
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.089627
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.088954
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.088829
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.088249
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.088028
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.090658
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.086884
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.085973
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.087107
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.084259
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.086904
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.085858
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.085546
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.087197
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.087778
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.087593
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.094662
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.087898
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.091904
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.085407
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.086316
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.087831
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.086733
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.086622
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.089277
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.088113
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.090506
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.086707
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.085389
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.085659
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.087594
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.089771
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.084883
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.089824
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.087499
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.087076
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.088966
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.090546
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.091019
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.090392
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.089823
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.086478
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.086112
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.087970
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.087332
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.089512
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.091250
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.089854
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.086523
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.087847
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.090130
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.104617
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.089964
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.090054
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.088026
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.088327
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.086541
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.084736
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.088239
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.086012
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.087843
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.086043
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.088630
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.088623
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.089012
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
Epoch 8 | Loss: 0.088203 | MSE: 0.087920 | MAE: 0.188691 | PSNR: 10.56 dB
About to log to wandb: {'epoch': 8, 'train_loss': 0.08820270709693431, 'eval_mse': np.float32(0.087919615), 'eval_mae': np.float32(0.18869142), 'eval_psnr': 10.559141916597433}
Logged to wandb.
    Saved comparison image: block_comparisons/epoch_008_block_00002.png
    Saved comparison image: block_comparisons/epoch_008_block_00000.png
    Saved comparison image: block_comparisons/epoch_008_block_00007.png

--- Epoch 9/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.089221
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.088651
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.086394
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.086964
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.088391
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.088844
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.086784
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.085274
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.086654
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.088273
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.087118
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.089151
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.085585
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.087948
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.090673
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.089629
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.087368
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.086023
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.087716
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.087847
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.086167
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.086565
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.088784
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.087610
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.085850
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.091278
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.094464
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.087024
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.087289
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.088109
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.088395
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.085779
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.088706
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.088008
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.088841
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.087198
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.088673
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.085528
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.092584
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.086249
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.087991
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.089344
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.088483
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.087434
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.088259
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.089609
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.090124
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.088360
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.089604
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.086421
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.087995
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.087644
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.089011
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.087374
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.086052
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.087259
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.087427
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.087862
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.086860
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.088135
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.095694
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.090658
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.087861
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.087126
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 66: Loss = 0.086375
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 67: Loss = 0.087442
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 68: Loss = 0.087576
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 69: Loss = 0.086246
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 70: Loss = 0.088542
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 71: Loss = 0.091131
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 72: Loss = 0.087081
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 73: Loss = 0.087242
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 74: Loss = 0.089838
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 75: Loss = 0.086486
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 76: Loss = 0.087222
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 77: Loss = 0.084227
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 78: Loss = 0.086219
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 79: Loss = 0.087064
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 80: Loss = 0.087967
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 81: Loss = 0.090694
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 82: Loss = 0.088024
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 83: Loss = 0.085880
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 84: Loss = 0.089029
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 85: Loss = 0.084824
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 86: Loss = 0.087799
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 87: Loss = 0.087615
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 88: Loss = 0.090011
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 89: Loss = 0.089493
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 90: Loss = 0.089626
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 91: Loss = 0.093349
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 92: Loss = 0.087270
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 93: Loss = 0.086005
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 94: Loss = 0.086569
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 95: Loss = 0.090172
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 96: Loss = 0.088933
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 97: Loss = 0.088336
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 98: Loss = 0.088870
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 99: Loss = 0.088047
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 100: Loss = 0.090540
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 101: Loss = 0.086358
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
Epoch 9 | Loss: 0.088083 | MSE: 0.087657 | MAE: 0.188976 | PSNR: 10.57 dB
About to log to wandb: {'epoch': 9, 'train_loss': 0.08808300957083702, 'eval_mse': np.float32(0.08765697), 'eval_mae': np.float32(0.1889765), 'eval_psnr': 10.572135058266367}
Logged to wandb.
    Saved comparison image: block_comparisons/epoch_009_block_00009.png
    Saved comparison image: block_comparisons/epoch_009_block_00004.png
    Saved comparison image: block_comparisons/epoch_009_block_00005.png

--- Epoch 10/100 ---
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 2: Loss = 0.085538
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 3: Loss = 0.086960
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 4: Loss = 0.087514
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 5: Loss = 0.089926
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 6: Loss = 0.089099
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 7: Loss = 0.086556
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 8: Loss = 0.087791
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 9: Loss = 0.088175
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 10: Loss = 0.086356
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 11: Loss = 0.090190
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 12: Loss = 0.090585
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 13: Loss = 0.091312
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 14: Loss = 0.086878
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 15: Loss = 0.087662
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 16: Loss = 0.088007
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 17: Loss = 0.086864
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 18: Loss = 0.086781
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 19: Loss = 0.088783
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 20: Loss = 0.090776
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 21: Loss = 0.090121
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 22: Loss = 0.087556
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 23: Loss = 0.087195
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 24: Loss = 0.087182
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 25: Loss = 0.087023
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 26: Loss = 0.086512
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 27: Loss = 0.090357
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 28: Loss = 0.087434
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 29: Loss = 0.089049
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 30: Loss = 0.095658
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 31: Loss = 0.088258
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 32: Loss = 0.087489
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 33: Loss = 0.086070
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 34: Loss = 0.090200
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 35: Loss = 0.092583
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 36: Loss = 0.087129
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 37: Loss = 0.089300
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 38: Loss = 0.088199
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 39: Loss = 0.088074
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 40: Loss = 0.086347
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 41: Loss = 0.089652
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 42: Loss = 0.086388
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 43: Loss = 0.088165
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 44: Loss = 0.088993
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 45: Loss = 0.085411
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 46: Loss = 0.089692
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 47: Loss = 0.090165
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 48: Loss = 0.086467
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 49: Loss = 0.087450
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 50: Loss = 0.088555
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 51: Loss = 0.086183
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 52: Loss = 0.086716
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 53: Loss = 0.086974
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 54: Loss = 0.090346
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 55: Loss = 0.091640
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 56: Loss = 0.088946
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 57: Loss = 0.087700
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 58: Loss = 0.088450
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 59: Loss = 0.088952
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 60: Loss = 0.086744
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 61: Loss = 0.087016
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 62: Loss = 0.087614
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 63: Loss = 0.088504
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 64: Loss = 0.087312
Batch shape: torch.Size([1, 10, 2, 50, 50])
MaskedBlockViT.forward called
  x_blocks shape: torch.Size([1, 10, 2, 50, 50])
  CNNBlockEncoder input shape: torch.Size([10, 2, 50, 50])
  CNNBlockEncoder output shape: torch.Size([10, 128])
  x_emb shape after encoder and view: torch.Size([1, 10, 128])
  x_emb shape after adding pos_embed_2d: torch.Size([1, 10, 128])
  x_masked shape: torch.Size([1, 7, 128])
  ids_keep shape: torch.Size([1, 7])
  ids_mask shape: torch.Size([1, 3])
  ids_restore shape: torch.Size([1, 10])
  encoded shape after transformer: torch.Size([1, 7, 128])
  decoder_input shape: torch.Size([1, 10, 128])
  linear_decoded shape: torch.Size([1, 10, 10816])
  conv_input shape: torch.Size([10, 64, 13, 13])
  pred_flat_conv shape: torch.Size([10, 2, 52, 52])
  Cropping pred_flat_conv from torch.Size([10, 2, 52, 52]) to (2, 50, 50)
x_blocks.shape: torch.Size([1, 10, 50, 50, 2])
  Batch 65: Loss = 0.088849
Traceback (most recent call last):
  File "/media/cc/2T/liouvilleViT/train_masked_blocks.py", line 188, in <module>
    run_training()
  File "/media/cc/2T/liouvilleViT/train_masked_blocks.py", line 133, in run_training
    for batch in dataloader:
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cc/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/media/cc/2T/liouvilleViT/multi_grid_dataset.py", line 29, in __getitem__
    block = data[idx].astype(np.float32)
KeyboardInterrupt
